console:
  quiet: False
  folder: /home/ubuntu/gengyuan/logging/pipeline
  format: {}
  log_level: info
  log_format: "%(asctime)s.%(msecs)03d - %(levelname)-8s - %(name)-30s - %(message)s (%(filename)s:%(lineno)s)"
  echo: True

#local
task:
  type: train
  device: 'cuda'
  reciprocal_training: False

random_seed:
  default: -1
  python: -1
  torch: -1
  numpy: -1
  numba: -1


# local
dataset:
  folder: /home/ubuntu/gengyuan/tkg-framework/data/icews14

  # indexes mapping [false, true]
  # TODO 可以保存到cache
  mapping: False
  filter: False
  temporal:
    resolution: "day"
    index: False
    float: True
  args: ~

  name: 'icews14'
  num_entities: -1
  num_relations: -1
  pickle: True

negative_sampling:
  type: 'time_agnostic'
  num_samples: 500
  filter: False
  as_matrix: True
  target: both
  args: ~


model:
  type: pipeline_model

  embedding:
    entity:
      pos_aware: True
      keys:
#        real:
#          dim: 100
#          init: xavier_uniform
#        imag:
#          dim: 100
#          init: xavier_uniform
        ent_embs:
          dim: 68
          init: xavier_uniform
        amps_y:
          dim: 32
          init: xavier_uniform
        amps_m:
          dim: 32
          init: xavier_uniform
        amps_d:
          dim: 32
          init: xavier_uniform
        freq_y:
          dim: 32
          init: xavier_uniform
        freq_m:
          dim: 32
          init: xavier_uniform
        freq_d:
          dim: 32
          init: xavier_uniform
        phi_y:
          dim: 32
          init: xavier_uniform
        phi_m:
          dim: 32
          init: xavier_uniform
        phi_d:
          dim: 32
          init: xavier_uniform

    relation:
      keys:
        real:
          dim: 100
          init: xavier_uniform
#        imag:
#          dim: 100
#          init: xavier_uniform
    # if temporal: ~ then we use float, otherwise we use the index
    temporal:
      keys:
        real:
          dim: 32
          init: xavier_uniform
#        imag:
#          dim: 100
#          init: xavier_uniform

  fusion:
    type: diachronic_entity_fusion
    target:
      - 'ent+temp'
    args: ~
  transformation:
    type: translation_tf
    gamma: 100
    p: 1
    range: 10
    args: ~
  scorer:
    inverse: True

  args: ~



train:
  # Split used for training (specified under 'data.files').
  split: train
  type: negative_sampling

  loss:
    type: cross_entropy_loss
    args: ~

  max_epochs: 500


  loader:
    num_workers: 0
    pin_memory: False
    drop_last: False
    timeout: 0

  valid:
    split: test # in [test or valid]
    every: 10
    batch_size: 100
    filter: time-aware  # in [off, static, time-aware]
    ordering: optimistic    # in [optimistic, peesimistic]
    k: [1, 3, 10]

  batch_size: 512
  subbatch_size: -1
  subbatch_auto_tune: False
  optimizer:
    type: Adam
    args:
      lr: 0.001

    default:
      type: Adam           # sgd, adagrad, adam

      args:
        +++: +++

  regularizer: ~
  inplace_regularizer: ~

  lr_scheduler: ""

  lr_scheduler_args:
    +++: +++

  trace_level: epoch           # batch, epoch

  checkpoint:
    folder: /home/ubuntu/gengyuan/ckpt/
    every: 10
    keep: 3

  auto_correct: False
  abort_on_nan: True
  visualize_graph: False

eval:
  filter: time-aware
  ordering: descending
  preference: optimistic
  k: [1,3,10]


